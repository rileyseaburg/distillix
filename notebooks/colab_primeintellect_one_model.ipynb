{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dd0e10",
   "metadata": {},
   "source": [
    "# PrimeIntellect SYNTHETIC-1 → Distillix → One Model (Colab-ready)\n",
    "\n",
    "This notebook builds a single training dataset from the **PrimeIntellect SYNTHETIC‑1** collection (multiple datasets), then **optionally trains one Distillix model** on the unified data.\n",
    "\n",
    "**What you get**\n",
    "- `data/training/unified_primeintellect.jsonl` in `{prompt,response,source,metadata}` format\n",
    "- (optional) a trained checkpoint under `artifacts/` via `scripts/train_codetether.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653fc65c",
   "metadata": {},
   "source": [
    "## 0) Setup (clone repo + install dependencies)\n",
    "\n",
    "Colab starts in `/content`. This cell:\n",
    "1. Clones the Distillix repo (or reuses it if already present)\n",
    "2. Installs minimal Python dependencies needed for data import + training\n",
    "\n",
    "> If you already uploaded the repo to Colab, set `REPO_DIR` accordingly and skip cloning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c69733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "print('Python:', sys.version.split()[0])\n",
    "print('Executable:', sys.executable)\n",
    "\n",
    "# ---- configure repo location ----\n",
    "REPO_URL = os.environ.get('DISTILLIX_REPO_URL', 'https://github.com/rileyseaburg/distillix.git')\n",
    "REPO_DIR = Path(os.environ.get('DISTILLIX_REPO_DIR', '/content/distillix')).resolve()\n",
    "\n",
    "print('Repo URL:', REPO_URL)\n",
    "print('Repo dir:', REPO_DIR)\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    subprocess.run(['git', 'clone', '--depth', '1', REPO_URL, str(REPO_DIR)], check=True)\n",
    "else:\n",
    "    print('Repo already exists, skipping clone.')\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print('CWD:', Path.cwd())\n",
    "\n",
    "# ---- install dependencies (minimal) ----\n",
    "deps = [\n",
    "    'datasets>=2.16.0',\n",
    "    'transformers>=4.36.0',\n",
    "    'tokenizers>=0.15.0',\n",
    "    'sentencepiece>=0.1.99',\n",
    "    'tqdm>=4.66.0',\n",
    "    'pyyaml>=6.0.1',\n",
    "    'pydantic>=2.5.0',\n",
    "    'numpy>=1.24.0',\n",
    "    'safetensors>=0.4.0',\n",
    "    'einops>=0.7.0',\n",
    "    # training utils\n",
    "    'rich>=13.7.0',\n",
    "    'typer>=0.9.0',\n",
    "    'python-dotenv>=1.0.0',\n",
    "    # torch is usually preinstalled in Colab; keep this optional\n",
    "    # 'torch>=2.1.0',\n",
    " ]\n",
    "\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', *deps], check=True)\n",
    "print('Installed deps OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e080f",
   "metadata": {},
   "source": [
    "## 1) Smoke test the pipeline (tiny limits)\n",
    "\n",
    "This is a quick sanity check that:\n",
    "- Hugging Face datasets import works\n",
    "- the per-dataset JSONLs are created\n",
    "- they combine into a unified JSONL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82916b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess, sys\n",
    "\n",
    "tmp_work = Path('/content/pi_work')\n",
    "tmp_unified = Path('/content/pi_unified.jsonl')\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, 'scripts/pipeline_primeintellect_one_model.py',\n",
    "    '--dataset', 'PrimeIntellect/verifiable-coding-problems=3',\n",
    "    '--dataset', 'PrimeIntellect/real-world-swe-problems=2',\n",
    "    '--work-dir', str(tmp_work),\n",
    "    '--unified-out', str(tmp_unified),\n",
    "    '--no-shuffle',\n",
    "    '--no-dedup',\n",
    " ]\n",
    "print('Running:', ' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n",
    "\n",
    "print('Unified exists:', tmp_unified.exists())\n",
    "print('Unified lines:', sum(1 for _ in tmp_unified.open('r', encoding='utf-8')))\n",
    "first = json.loads(tmp_unified.open('r', encoding='utf-8').readline())\n",
    "print('Keys:', sorted(first.keys()))\n",
    "print('Source:', first.get('source'))\n",
    "print('Prompt preview:', first.get('prompt','')[:200].replace('\\n','\\\\n'))\n",
    "print('Response preview:', first.get('response','')[:200].replace('\\n','\\\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f899e18",
   "metadata": {},
   "source": [
    "## 2) Build a real unified dataset (capped)\n",
    "\n",
    "These caps keep it runnable in Colab without downloading the full parquet corpora.\n",
    "You can increase limits later once everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11857e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, sys\n",
    "\n",
    "work_dir = Path('data/training/primeintellect_pipeline')\n",
    "unified_out = Path('data/training/unified_primeintellect.jsonl')\n",
    "\n",
    "dataset_specs = [\n",
    "    'PrimeIntellect/SYNTHETIC-1-SFT-Data=20000',\n",
    "    'PrimeIntellect/verifiable-coding-problems=20000',\n",
    "    'PrimeIntellect/real-world-swe-problems=10000',\n",
    "    'PrimeIntellect/synthetic-code-understanding=10000',\n",
    "    'PrimeIntellect/stackexchange-question-answering=10000',\n",
    " ]\n",
    "\n",
    "cmd = [sys.executable, 'scripts/pipeline_primeintellect_one_model.py']\n",
    "for spec in dataset_specs:\n",
    "    cmd += ['--dataset', spec]\n",
    "cmd += ['--work-dir', str(work_dir), '--unified-out', str(unified_out)]\n",
    "\n",
    "print('Running:', ' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n",
    "\n",
    "print('Unified path:', unified_out)\n",
    "print('Unified lines:', sum(1 for _ in unified_out.open('r', encoding='utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61d529",
   "metadata": {},
   "source": [
    "## 3) Inspect the unified JSONL\n",
    "\n",
    "> This is optional but recommended: sanity check the mixture by `source`, and check average prompt/response sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "path = Path('data/training/unified_primeintellect.jsonl')\n",
    "assert path.exists(), f\"Missing: {path}\"\n",
    "\n",
    "counts = Counter()\n",
    "lens = defaultdict(lambda: {'p': 0, 'r': 0, 'n': 0})\n",
    "examples_by_source = defaultdict(list)\n",
    "\n",
    "max_lines = 2000  # keep cheap in Colab\n",
    "for i, line in enumerate(path.open('r', encoding='utf-8')):\n",
    "    if i >= max_lines:\n",
    "        break\n",
    "    obj = json.loads(line)\n",
    "    src = obj.get('source', 'unknown')\n",
    "    p = obj.get('prompt', '')\n",
    "    r = obj.get('response', '')\n",
    "\n",
    "    counts[src] += 1\n",
    "    lens[src]['p'] += len(p)\n",
    "    lens[src]['r'] += len(r)\n",
    "    lens[src]['n'] += 1\n",
    "\n",
    "    if len(examples_by_source[src]) < 3:\n",
    "        examples_by_source[src].append(obj)\n",
    "\n",
    "print('Counts (first', max_lines, 'rows):')\n",
    "for src, c in counts.most_common():\n",
    "    n = lens[src]['n']\n",
    "    ap = lens[src]['p'] / max(1, n)\n",
    "    ar = lens[src]['r'] / max(1, n)\n",
    "    print(f\"- {src}: {c} | avg_prompt_chars={ap:.0f} avg_response_chars={ar:.0f}\")\n",
    "\n",
    "# show 2 random examples from two different sources (if available)\n",
    "sources = list(examples_by_source.keys())\n",
    "random.shuffle(sources)\n",
    "for src in sources[:2]:\n",
    "    ex = examples_by_source[src][0]\n",
    "    print('\\n--- example source:', src, '---')\n",
    "    print('PROMPT:', ex['prompt'][:400])\n",
    "    print('\\nRESPONSE:', ex['response'][:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28a07f",
   "metadata": {},
   "source": [
    "## 4) Optional: Train one model\n",
    "\n",
    "> **GPU recommended.** This uses `scripts/train_codetether.py` and expects CUDA to be available.\n",
    "\n",
    "This repo historically suffered from BitNet weight collapse; this run enables the anti-collapse polarization hook by default when `RUN_TRAIN=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "RUN_TRAIN = False  # <- set True to actually train\n",
    "\n",
    "if RUN_TRAIN:\n",
    "    data_path = Path('data/training/unified_primeintellect.jsonl')\n",
    "    assert data_path.exists(), f\"Missing: {data_path}\"\n",
    "\n",
    "    # Pick a healthy-ish base checkpoint if present.\n",
    "    base = Path('artifacts/distillix-v05-1500steps.pt')\n",
    "    if not base.exists():\n",
    "        # fallback: you can swap this to any base you have\n",
    "        base = Path('artifacts/distillix-v05-500steps.pt')\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable, 'scripts/train_codetether.py',\n",
    "        '--base', str(base),\n",
    "        '--data', str(data_path),\n",
    "        '--output', 'distillix-primeintellect',\n",
    "        '--steps', '1000',\n",
    "        '--batch', '4',\n",
    "        '--accum', '8',\n",
    "        '--muon-weight-decay', '0.0',\n",
    "        '--adamw-weight-decay', '0.0',\n",
    "        '--polarize',\n",
    "        '--target-scale', '0.01',\n",
    "        '--polarization-strength', '0.1',\n",
    "    ]\n",
    "\n",
    "    print('Running training:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "else:\n",
    "    print('RUN_TRAIN=False (skipping). Set it to True to launch training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425519d8",
   "metadata": {},
   "source": [
    "## 5) Troubleshooting\n",
    "\n",
    "- **Native abort after Hugging Face streaming**: In some environments, `datasets.load_dataset(..., streaming=True)` can abort during interpreter shutdown. This repo’s importer (`scripts/import_hf_synthetic1.py`) uses a hard-exit after flushing output to avoid that. The pipeline runs the importer in a subprocess so your notebook stays alive.\n",
    "- **Disk usage**: The raw SYNTHETIC‑1 dataset is large. Keep limits small until you’re happy with the mixture.\n",
    "- **CUDA**: `scripts/train_codetether.py` currently moves the model to CUDA. In Colab, switch Runtime → Change runtime type → GPU."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
